<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />

<meta name="viewport" content="width=device-width, initial-scale=1">

<meta name="author" content="Manish Saraswat" />

<meta name="date" content="2019-05-11" />

<title>Introduction to SuperML</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>



<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23header%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%20code%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />

</head>

<body>




<h1 class="title toc-ignore">Introduction to SuperML</h1>
<h4 class="author"><em>Manish Saraswat</em></h4>
<h4 class="date"><em>2019-05-11</em></h4>



<p>SuperML R package is designed to unify the model training process in R like Python. Generally, it’s seen that people spend lot of time in searching for packages, figuring out the syntax for training machine learning models in R. This behaviour is highly apparent in users who frequently switch between R and Python. This package provides a python´s scikit-learn interface (<code>fit</code>, <code>predict</code>) to train models faster.</p>
<p>In addition to building machine learning models, there are handy functionalities to do feature engineering</p>
<p>This ambitious package is my ongoing effort to help the r-community build ML models easily and faster in R.</p>
<div id="install" class="section level2">
<h2>Install</h2>
<p>You can install latest cran version using (recommended):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">&quot;superml&quot;</span>)</code></pre></div>
<p>You can install the developmemt version directly from github using:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">devtools<span class="op">::</span><span class="kw">install_github</span>(<span class="st">&quot;saraswatmks/superml&quot;</span>)</code></pre></div>
</div>
<div id="examples---machine-learning-models" class="section level2">
<h2>Examples - Machine Learning Models</h2>
<p>This package uses existing r-packages to build machine learning model. In this tutorial, we’ll use data.table R package to do all tasks related to data manipulation.</p>
<div id="regression-data" class="section level3">
<h3>Regression Data</h3>
<p>We’ll quickly prepare the data set to be ready to served for model training.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">load</span>(<span class="st">&quot;../data/reg_train.rda&quot;</span>)
<span class="co"># if the above doesn't work, you can try: load(&quot;reg_train.rda&quot;)</span>

<span class="kw">library</span>(data.table)
<span class="kw">library</span>(caret)
<span class="co">#&gt; Loading required package: lattice</span>
<span class="co">#&gt; Loading required package: ggplot2</span>
<span class="kw">library</span>(superml)
<span class="co">#&gt; Loading required package: R6</span>

<span class="kw">library</span>(Metrics)
<span class="co">#&gt; </span>
<span class="co">#&gt; Attaching package: 'Metrics'</span>
<span class="co">#&gt; The following objects are masked from 'package:caret':</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     precision, recall</span>

<span class="kw">head</span>(reg_train)
<span class="co">#&gt;    Id MSSubClass MSZoning LotFrontage LotArea Street Alley LotShape</span>
<span class="co">#&gt; 1:  1         60       RL          65    8450   Pave  &lt;NA&gt;      Reg</span>
<span class="co">#&gt; 2:  2         20       RL          80    9600   Pave  &lt;NA&gt;      Reg</span>
<span class="co">#&gt; 3:  3         60       RL          68   11250   Pave  &lt;NA&gt;      IR1</span>
<span class="co">#&gt; 4:  4         70       RL          60    9550   Pave  &lt;NA&gt;      IR1</span>
<span class="co">#&gt; 5:  5         60       RL          84   14260   Pave  &lt;NA&gt;      IR1</span>
<span class="co">#&gt; 6:  6         50       RL          85   14115   Pave  &lt;NA&gt;      IR1</span>
<span class="co">#&gt;    LandContour Utilities LotConfig LandSlope Neighborhood Condition1</span>
<span class="co">#&gt; 1:         Lvl    AllPub    Inside       Gtl      CollgCr       Norm</span>
<span class="co">#&gt; 2:         Lvl    AllPub       FR2       Gtl      Veenker      Feedr</span>
<span class="co">#&gt; 3:         Lvl    AllPub    Inside       Gtl      CollgCr       Norm</span>
<span class="co">#&gt; 4:         Lvl    AllPub    Corner       Gtl      Crawfor       Norm</span>
<span class="co">#&gt; 5:         Lvl    AllPub       FR2       Gtl      NoRidge       Norm</span>
<span class="co">#&gt; 6:         Lvl    AllPub    Inside       Gtl      Mitchel       Norm</span>
<span class="co">#&gt;    Condition2 BldgType HouseStyle OverallQual OverallCond YearBuilt</span>
<span class="co">#&gt; 1:       Norm     1Fam     2Story           7           5      2003</span>
<span class="co">#&gt; 2:       Norm     1Fam     1Story           6           8      1976</span>
<span class="co">#&gt; 3:       Norm     1Fam     2Story           7           5      2001</span>
<span class="co">#&gt; 4:       Norm     1Fam     2Story           7           5      1915</span>
<span class="co">#&gt; 5:       Norm     1Fam     2Story           8           5      2000</span>
<span class="co">#&gt; 6:       Norm     1Fam     1.5Fin           5           5      1993</span>
<span class="co">#&gt;    YearRemodAdd RoofStyle RoofMatl Exterior1st Exterior2nd MasVnrType</span>
<span class="co">#&gt; 1:         2003     Gable  CompShg     VinylSd     VinylSd    BrkFace</span>
<span class="co">#&gt; 2:         1976     Gable  CompShg     MetalSd     MetalSd       None</span>
<span class="co">#&gt; 3:         2002     Gable  CompShg     VinylSd     VinylSd    BrkFace</span>
<span class="co">#&gt; 4:         1970     Gable  CompShg     Wd Sdng     Wd Shng       None</span>
<span class="co">#&gt; 5:         2000     Gable  CompShg     VinylSd     VinylSd    BrkFace</span>
<span class="co">#&gt; 6:         1995     Gable  CompShg     VinylSd     VinylSd       None</span>
<span class="co">#&gt;    MasVnrArea ExterQual ExterCond Foundation BsmtQual BsmtCond</span>
<span class="co">#&gt; 1:        196        Gd        TA      PConc       Gd       TA</span>
<span class="co">#&gt; 2:          0        TA        TA     CBlock       Gd       TA</span>
<span class="co">#&gt; 3:        162        Gd        TA      PConc       Gd       TA</span>
<span class="co">#&gt; 4:          0        TA        TA     BrkTil       TA       Gd</span>
<span class="co">#&gt; 5:        350        Gd        TA      PConc       Gd       TA</span>
<span class="co">#&gt; 6:          0        TA        TA       Wood       Gd       TA</span>
<span class="co">#&gt;    BsmtExposure BsmtFinType1 BsmtFinSF1 BsmtFinType2 BsmtFinSF2 BsmtUnfSF</span>
<span class="co">#&gt; 1:           No          GLQ        706          Unf          0       150</span>
<span class="co">#&gt; 2:           Gd          ALQ        978          Unf          0       284</span>
<span class="co">#&gt; 3:           Mn          GLQ        486          Unf          0       434</span>
<span class="co">#&gt; 4:           No          ALQ        216          Unf          0       540</span>
<span class="co">#&gt; 5:           Av          GLQ        655          Unf          0       490</span>
<span class="co">#&gt; 6:           No          GLQ        732          Unf          0        64</span>
<span class="co">#&gt;    TotalBsmtSF Heating HeatingQC CentralAir Electrical 1stFlrSF 2ndFlrSF</span>
<span class="co">#&gt; 1:         856    GasA        Ex          Y      SBrkr      856      854</span>
<span class="co">#&gt; 2:        1262    GasA        Ex          Y      SBrkr     1262        0</span>
<span class="co">#&gt; 3:         920    GasA        Ex          Y      SBrkr      920      866</span>
<span class="co">#&gt; 4:         756    GasA        Gd          Y      SBrkr      961      756</span>
<span class="co">#&gt; 5:        1145    GasA        Ex          Y      SBrkr     1145     1053</span>
<span class="co">#&gt; 6:         796    GasA        Ex          Y      SBrkr      796      566</span>
<span class="co">#&gt;    LowQualFinSF GrLivArea BsmtFullBath BsmtHalfBath FullBath HalfBath</span>
<span class="co">#&gt; 1:            0      1710            1            0        2        1</span>
<span class="co">#&gt; 2:            0      1262            0            1        2        0</span>
<span class="co">#&gt; 3:            0      1786            1            0        2        1</span>
<span class="co">#&gt; 4:            0      1717            1            0        1        0</span>
<span class="co">#&gt; 5:            0      2198            1            0        2        1</span>
<span class="co">#&gt; 6:            0      1362            1            0        1        1</span>
<span class="co">#&gt;    BedroomAbvGr KitchenAbvGr KitchenQual TotRmsAbvGrd Functional</span>
<span class="co">#&gt; 1:            3            1          Gd            8        Typ</span>
<span class="co">#&gt; 2:            3            1          TA            6        Typ</span>
<span class="co">#&gt; 3:            3            1          Gd            6        Typ</span>
<span class="co">#&gt; 4:            3            1          Gd            7        Typ</span>
<span class="co">#&gt; 5:            4            1          Gd            9        Typ</span>
<span class="co">#&gt; 6:            1            1          TA            5        Typ</span>
<span class="co">#&gt;    Fireplaces FireplaceQu GarageType GarageYrBlt GarageFinish GarageCars</span>
<span class="co">#&gt; 1:          0        &lt;NA&gt;     Attchd        2003          RFn          2</span>
<span class="co">#&gt; 2:          1          TA     Attchd        1976          RFn          2</span>
<span class="co">#&gt; 3:          1          TA     Attchd        2001          RFn          2</span>
<span class="co">#&gt; 4:          1          Gd     Detchd        1998          Unf          3</span>
<span class="co">#&gt; 5:          1          TA     Attchd        2000          RFn          3</span>
<span class="co">#&gt; 6:          0        &lt;NA&gt;     Attchd        1993          Unf          2</span>
<span class="co">#&gt;    GarageArea GarageQual GarageCond PavedDrive WoodDeckSF OpenPorchSF</span>
<span class="co">#&gt; 1:        548         TA         TA          Y          0          61</span>
<span class="co">#&gt; 2:        460         TA         TA          Y        298           0</span>
<span class="co">#&gt; 3:        608         TA         TA          Y          0          42</span>
<span class="co">#&gt; 4:        642         TA         TA          Y          0          35</span>
<span class="co">#&gt; 5:        836         TA         TA          Y        192          84</span>
<span class="co">#&gt; 6:        480         TA         TA          Y         40          30</span>
<span class="co">#&gt;    EnclosedPorch 3SsnPorch ScreenPorch PoolArea PoolQC Fence MiscFeature</span>
<span class="co">#&gt; 1:             0         0           0        0   &lt;NA&gt;  &lt;NA&gt;        &lt;NA&gt;</span>
<span class="co">#&gt; 2:             0         0           0        0   &lt;NA&gt;  &lt;NA&gt;        &lt;NA&gt;</span>
<span class="co">#&gt; 3:             0         0           0        0   &lt;NA&gt;  &lt;NA&gt;        &lt;NA&gt;</span>
<span class="co">#&gt; 4:           272         0           0        0   &lt;NA&gt;  &lt;NA&gt;        &lt;NA&gt;</span>
<span class="co">#&gt; 5:             0         0           0        0   &lt;NA&gt;  &lt;NA&gt;        &lt;NA&gt;</span>
<span class="co">#&gt; 6:             0       320           0        0   &lt;NA&gt; MnPrv        Shed</span>
<span class="co">#&gt;    MiscVal MoSold YrSold SaleType SaleCondition SalePrice</span>
<span class="co">#&gt; 1:       0      2   2008       WD        Normal    208500</span>
<span class="co">#&gt; 2:       0      5   2007       WD        Normal    181500</span>
<span class="co">#&gt; 3:       0      9   2008       WD        Normal    223500</span>
<span class="co">#&gt; 4:       0      2   2006       WD       Abnorml    140000</span>
<span class="co">#&gt; 5:       0     12   2008       WD        Normal    250000</span>
<span class="co">#&gt; 6:     700     10   2009       WD        Normal    143000</span>

split &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">y =</span> reg_train<span class="op">$</span>SalePrice, <span class="dt">p =</span> <span class="fl">0.7</span>)
xtrain &lt;-<span class="st"> </span>reg_train[split<span class="op">$</span>Resample1]
xtest &lt;-<span class="st"> </span>reg_train[<span class="op">!</span>split<span class="op">$</span>Resample1]</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># remove features with 90% or more missing values</span>
<span class="co"># we will also remove the Id column because it doesn't contain</span>
<span class="co"># any useful information</span>
na_cols &lt;-<span class="st"> </span><span class="kw">colSums</span>(<span class="kw">is.na</span>(xtrain)) <span class="op">/</span><span class="st"> </span><span class="kw">nrow</span>(xtrain)
na_cols &lt;-<span class="st"> </span><span class="kw">names</span>(na_cols[<span class="kw">which</span>(na_cols <span class="op">&gt;</span><span class="st"> </span><span class="fl">0.9</span>)])

xtrain[, <span class="kw">c</span>(na_cols, <span class="st">&quot;Id&quot;</span>) <span class="op">:</span><span class="er">=</span><span class="st"> </span><span class="ot">NULL</span>]
xtest[, <span class="kw">c</span>(na_cols, <span class="st">&quot;Id&quot;</span>) <span class="op">:</span><span class="er">=</span><span class="st"> </span><span class="ot">NULL</span>]

<span class="co"># encode categorical variables</span>
cat_cols &lt;-<span class="st"> </span><span class="kw">names</span>(xtrain)[<span class="kw">sapply</span>(xtrain, is.character)]

<span class="cf">for</span>(c <span class="cf">in</span> cat_cols){
    lbl &lt;-<span class="st"> </span>LabelEncoder<span class="op">$</span><span class="kw">new</span>()
    lbl<span class="op">$</span><span class="kw">fit</span>(<span class="kw">c</span>(xtrain[[c]], xtest[[c]]))
    xtrain[[c]] &lt;-<span class="st"> </span>lbl<span class="op">$</span><span class="kw">transform</span>(xtrain[[c]])
    xtest[[c]] &lt;-<span class="st"> </span>lbl<span class="op">$</span><span class="kw">transform</span>(xtest[[c]])
}
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA' </span>
<span class="co">#&gt; The data contains NA values. Imputing NA with 'NA'</span>

<span class="co"># removing noise column</span>
noise &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">'GrLivArea'</span>,<span class="st">'TotalBsmtSF'</span>)

xtrain[, <span class="kw">c</span>(noise) <span class="op">:</span><span class="er">=</span><span class="st"> </span><span class="ot">NULL</span>]
xtest[, <span class="kw">c</span>(noise) <span class="op">:</span><span class="er">=</span><span class="st"> </span><span class="ot">NULL</span>]

<span class="co"># fill missing value with  -1</span>
xtrain[<span class="kw">is.na</span>(xtrain)] &lt;-<span class="st"> </span><span class="op">-</span><span class="dv">1</span>
xtest[<span class="kw">is.na</span>(xtest)] &lt;-<span class="st"> </span><span class="op">-</span><span class="dv">1</span></code></pre></div>
<p><strong>KNN Regression</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knn &lt;-<span class="st"> </span>KNNTrainer<span class="op">$</span><span class="kw">new</span>(<span class="dt">k =</span> <span class="dv">2</span>,<span class="dt">prob =</span> T,<span class="dt">type =</span> <span class="st">'reg'</span>)
knn<span class="op">$</span><span class="kw">fit</span>(<span class="dt">train =</span> xtrain, <span class="dt">test =</span> xtest, <span class="dt">y =</span> <span class="st">'SalePrice'</span>)
probs &lt;-<span class="st"> </span>knn<span class="op">$</span><span class="kw">predict</span>(<span class="dt">type =</span> <span class="st">'prob'</span>)
labels &lt;-<span class="st"> </span>knn<span class="op">$</span><span class="kw">predict</span>(<span class="dt">type=</span><span class="st">'raw'</span>)
<span class="kw">rmse</span>(<span class="dt">actual =</span> xtest<span class="op">$</span>SalePrice, <span class="dt">predicted=</span>labels)
<span class="co">#&gt; [1] 4799.556</span></code></pre></div>
<p><strong>SVM Regression</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">svm &lt;-<span class="st"> </span>SVMTrainer<span class="op">$</span><span class="kw">new</span>()
<span class="co">#&gt; [1] &quot;For classification, target variable must be factor type. For regression, target variable must be numeric type.&quot;</span>
svm<span class="op">$</span><span class="kw">fit</span>(xtrain, <span class="st">'SalePrice'</span>)
<span class="co">#&gt; Warning in svm.default(x = dataX, y = X[[y]], type = self$type, kernel =</span>
<span class="co">#&gt; self$kernel): Variable(s) 'Utilities' constant. Cannot scale data.</span>
pred &lt;-<span class="st"> </span>svm<span class="op">$</span><span class="kw">predict</span>(xtest)
<span class="kw">rmse</span>(<span class="dt">actual =</span> xtest<span class="op">$</span>SalePrice, <span class="dt">predicted =</span> pred)
<span class="co">#&gt; [1] 82964.99</span></code></pre></div>
<p><strong>Simple Regresison</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lf &lt;-<span class="st"> </span>LMTrainer<span class="op">$</span><span class="kw">new</span>(<span class="dt">family=</span><span class="st">&quot;gaussian&quot;</span>)
lf<span class="op">$</span><span class="kw">fit</span>(<span class="dt">X =</span> xtrain, <span class="dt">y =</span> <span class="st">&quot;SalePrice&quot;</span>)
<span class="kw">summary</span>(lf<span class="op">$</span>model)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; stats::glm(formula = f, family = self$family, data = X, weights = self$weights)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;     Min       1Q   Median       3Q      Max  </span>
<span class="co">#&gt; -353897   -13524     -994    13091   200214  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients: (1 not defined because of singularities)</span>
<span class="co">#&gt;                 Estimate Std. Error t value Pr(&gt;|t|)    </span>
<span class="co">#&gt; (Intercept)   -2.221e+06  1.460e+06  -1.522 0.128386    </span>
<span class="co">#&gt; MSSubClass    -7.534e+01  4.926e+01  -1.529 0.126512    </span>
<span class="co">#&gt; MSZoning      -1.421e+03  1.347e+03  -1.055 0.291704    </span>
<span class="co">#&gt; LotFrontage    4.875e+01  3.091e+01   1.577 0.115140    </span>
<span class="co">#&gt; LotArea        3.636e-01  1.305e-01   2.786 0.005441 ** </span>
<span class="co">#&gt; Street        -7.383e+03  2.132e+04  -0.346 0.729165    </span>
<span class="co">#&gt; LotShape       4.074e+03  1.804e+03   2.258 0.024159 *  </span>
<span class="co">#&gt; LandContour   -4.131e+03  2.124e+03  -1.945 0.052082 .  </span>
<span class="co">#&gt; Utilities             NA         NA      NA       NA    </span>
<span class="co">#&gt; LotConfig      6.803e+02  1.240e+03   0.548 0.583536    </span>
<span class="co">#&gt; LandSlope      7.990e+03  4.981e+03   1.604 0.109014    </span>
<span class="co">#&gt; Neighborhood   4.910e+01  1.677e+02   0.293 0.769746    </span>
<span class="co">#&gt; Condition1    -3.255e+03  7.961e+02  -4.089 4.70e-05 ***</span>
<span class="co">#&gt; Condition2    -1.161e+04  3.023e+03  -3.841 0.000131 ***</span>
<span class="co">#&gt; BldgType      -9.726e+02  1.906e+03  -0.510 0.610019    </span>
<span class="co">#&gt; HouseStyle    -7.974e+02  8.378e+02  -0.952 0.341455    </span>
<span class="co">#&gt; OverallQual    1.399e+04  1.295e+03  10.808  &lt; 2e-16 ***</span>
<span class="co">#&gt; OverallCond    6.684e+03  1.143e+03   5.846 6.94e-09 ***</span>
<span class="co">#&gt; YearBuilt      3.330e+02  7.492e+01   4.445 9.81e-06 ***</span>
<span class="co">#&gt; YearRemodAdd   2.024e+02  7.231e+01   2.799 0.005236 ** </span>
<span class="co">#&gt; RoofStyle     -8.664e+02  1.912e+03  -0.453 0.650469    </span>
<span class="co">#&gt; RoofMatl       3.548e+03  2.842e+03   1.248 0.212186    </span>
<span class="co">#&gt; Exterior1st   -2.247e+03  6.128e+02  -3.666 0.000260 ***</span>
<span class="co">#&gt; Exterior2nd    1.268e+03  5.999e+02   2.113 0.034883 *  </span>
<span class="co">#&gt; MasVnrType     3.244e+03  1.358e+03   2.389 0.017088 *  </span>
<span class="co">#&gt; MasVnrArea     3.127e+01  7.620e+00   4.104 4.41e-05 ***</span>
<span class="co">#&gt; ExterQual      5.809e+03  2.185e+03   2.659 0.007980 ** </span>
<span class="co">#&gt; ExterCond     -6.560e+02  2.293e+03  -0.286 0.774889    </span>
<span class="co">#&gt; Foundation    -1.975e+03  1.439e+03  -1.372 0.170314    </span>
<span class="co">#&gt; BsmtQual       3.406e+03  1.414e+03   2.410 0.016161 *  </span>
<span class="co">#&gt; BsmtCond      -4.149e+02  1.410e+03  -0.294 0.768575    </span>
<span class="co">#&gt; BsmtExposure   4.595e+03  9.043e+02   5.081 4.52e-07 ***</span>
<span class="co">#&gt; BsmtFinType1  -7.056e+02  7.072e+02  -0.998 0.318674    </span>
<span class="co">#&gt; BsmtFinSF1     3.748e+01  5.305e+00   7.065 3.11e-12 ***</span>
<span class="co">#&gt; BsmtFinType2  -7.229e+02  1.091e+03  -0.663 0.507630    </span>
<span class="co">#&gt; BsmtFinSF2     2.890e+01  9.445e+00   3.060 0.002274 ** </span>
<span class="co">#&gt; BsmtUnfSF      2.033e+01  4.942e+00   4.114 4.23e-05 ***</span>
<span class="co">#&gt; Heating        2.993e+03  3.912e+03   0.765 0.444404    </span>
<span class="co">#&gt; HeatingQC     -3.033e+03  1.298e+03  -2.337 0.019625 *  </span>
<span class="co">#&gt; CentralAir     4.238e+03  5.063e+03   0.837 0.402785    </span>
<span class="co">#&gt; Electrical     1.158e+03  1.935e+03   0.599 0.549646    </span>
<span class="co">#&gt; `1stFlrSF`     4.770e+01  6.367e+00   7.492 1.55e-13 ***</span>
<span class="co">#&gt; `2ndFlrSF`     4.719e+01  5.478e+00   8.615  &lt; 2e-16 ***</span>
<span class="co">#&gt; LowQualFinSF   3.766e+01  1.922e+01   1.960 0.050276 .  </span>
<span class="co">#&gt; BsmtFullBath   3.015e+03  2.726e+03   1.106 0.269013    </span>
<span class="co">#&gt; BsmtHalfBath  -1.583e+03  4.232e+03  -0.374 0.708412    </span>
<span class="co">#&gt; FullBath       3.840e+03  2.932e+03   1.309 0.190706    </span>
<span class="co">#&gt; HalfBath       2.834e+03  2.709e+03   1.046 0.295724    </span>
<span class="co">#&gt; BedroomAbvGr  -6.920e+03  1.788e+03  -3.870 0.000116 ***</span>
<span class="co">#&gt; KitchenAbvGr  -2.144e+04  5.518e+03  -3.885 0.000109 ***</span>
<span class="co">#&gt; KitchenQual    8.419e+03  1.674e+03   5.030 5.87e-07 ***</span>
<span class="co">#&gt; TotRmsAbvGrd   3.792e+03  1.286e+03   2.949 0.003270 ** </span>
<span class="co">#&gt; Functional    -5.979e+03  1.185e+03  -5.046 5.41e-07 ***</span>
<span class="co">#&gt; Fireplaces     4.213e+03  2.422e+03   1.739 0.082312 .  </span>
<span class="co">#&gt; FireplaceQu    9.087e+02  1.321e+03   0.688 0.491702    </span>
<span class="co">#&gt; GarageType     1.555e+03  1.200e+03   1.296 0.195144    </span>
<span class="co">#&gt; GarageYrBlt    3.340e+00  5.133e+00   0.651 0.515338    </span>
<span class="co">#&gt; GarageFinish   1.756e+03  1.361e+03   1.290 0.197236    </span>
<span class="co">#&gt; GarageCars     5.865e+03  3.066e+03   1.913 0.056066 .  </span>
<span class="co">#&gt; GarageArea     2.649e+01  9.994e+00   2.650 0.008181 ** </span>
<span class="co">#&gt; GarageQual     4.982e+03  2.843e+03   1.752 0.080033 .  </span>
<span class="co">#&gt; GarageCond    -3.004e+03  2.347e+03  -1.280 0.200830    </span>
<span class="co">#&gt; PavedDrive     4.637e+02  2.976e+03   0.156 0.876210    </span>
<span class="co">#&gt; WoodDeckSF     1.627e+01  8.232e+00   1.976 0.048448 *  </span>
<span class="co">#&gt; OpenPorchSF    1.075e+00  1.527e+01   0.070 0.943895    </span>
<span class="co">#&gt; EnclosedPorch  3.943e+01  1.744e+01   2.261 0.023961 *  </span>
<span class="co">#&gt; `3SsnPorch`    6.032e+01  4.144e+01   1.455 0.145874    </span>
<span class="co">#&gt; ScreenPorch    3.843e+01  1.766e+01   2.176 0.029770 *  </span>
<span class="co">#&gt; PoolArea       1.971e+01  2.987e+01   0.660 0.509643    </span>
<span class="co">#&gt; Fence         -2.273e+03  1.157e+03  -1.965 0.049758 *  </span>
<span class="co">#&gt; MiscVal        1.056e+00  1.650e+00   0.640 0.522259    </span>
<span class="co">#&gt; MoSold        -2.625e+02  3.501e+02  -0.750 0.453577    </span>
<span class="co">#&gt; YrSold         5.353e+02  7.241e+02   0.739 0.459982    </span>
<span class="co">#&gt; SaleType       2.102e+03  1.113e+03   1.889 0.059217 .  </span>
<span class="co">#&gt; SaleCondition  1.419e+03  1.250e+03   1.135 0.256781    </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for gaussian family taken to be 816314422)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 6.3448e+12  on 1023  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 7.7550e+11  on  950  degrees of freedom</span>
<span class="co">#&gt; AIC: 23992</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 2</span>
predictions &lt;-<span class="st"> </span>lf<span class="op">$</span><span class="kw">predict</span>(<span class="dt">df =</span> xtest)
<span class="co">#&gt; Warning in predict.lm(object, newdata, se.fit, scale = 1, type =</span>
<span class="co">#&gt; ifelse(type == : prediction from a rank-deficient fit may be misleading</span>
<span class="kw">rmse</span>(<span class="dt">actual =</span> xtest<span class="op">$</span>SalePrice, <span class="dt">predicted =</span> predictions)
<span class="co">#&gt; [1] 43857.05</span></code></pre></div>
<p><strong>Lasso Regression</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lf &lt;-<span class="st"> </span>LMTrainer<span class="op">$</span><span class="kw">new</span>(<span class="dt">family =</span> <span class="st">&quot;gaussian&quot;</span>, <span class="dt">alpha=</span><span class="dv">1</span>, <span class="dt">lambda =</span> <span class="dv">1000</span>)
lf<span class="op">$</span><span class="kw">fit</span>(<span class="dt">X =</span> xtrain, <span class="dt">y =</span> <span class="st">&quot;SalePrice&quot;</span>)
predictions &lt;-<span class="st"> </span>lf<span class="op">$</span><span class="kw">predict</span>(<span class="dt">df =</span> xtest)
<span class="kw">rmse</span>(<span class="dt">actual =</span> xtest<span class="op">$</span>SalePrice, <span class="dt">predicted =</span> predictions)
<span class="co">#&gt; [1] 49210.68</span></code></pre></div>
<p><strong>Ridge Regression</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lf &lt;-<span class="st"> </span>LMTrainer<span class="op">$</span><span class="kw">new</span>(<span class="dt">family =</span> <span class="st">&quot;gaussian&quot;</span>, <span class="dt">alpha=</span><span class="dv">0</span>)
lf<span class="op">$</span><span class="kw">fit</span>(<span class="dt">X =</span> xtrain, <span class="dt">y =</span> <span class="st">&quot;SalePrice&quot;</span>)
predictions &lt;-<span class="st"> </span>lf<span class="op">$</span><span class="kw">predict</span>(<span class="dt">df =</span> xtest)
<span class="kw">rmse</span>(<span class="dt">actual =</span> xtest<span class="op">$</span>SalePrice, <span class="dt">predicted =</span> predictions)
<span class="co">#&gt; [1] 49740.23</span></code></pre></div>
<p><strong>Logistic Regression with CV</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lf &lt;-<span class="st"> </span>LMTrainer<span class="op">$</span><span class="kw">new</span>(<span class="dt">family =</span> <span class="st">&quot;gaussian&quot;</span>)
lf<span class="op">$</span><span class="kw">cv_model</span>(<span class="dt">X =</span> xtrain, <span class="dt">y =</span> <span class="st">'SalePrice'</span>, <span class="dt">nfolds =</span> <span class="dv">5</span>, <span class="dt">parallel =</span> <span class="ot">FALSE</span>)
<span class="co">#&gt; Computation done.</span>
predictions &lt;-<span class="st"> </span>lf<span class="op">$</span><span class="kw">cv_predict</span>(<span class="dt">df =</span> xtest)
coefs &lt;-<span class="st"> </span>lf<span class="op">$</span><span class="kw">get_importance</span>()
<span class="kw">rmse</span>(<span class="dt">actual =</span> xtest<span class="op">$</span>SalePrice, <span class="dt">predicted =</span> predictions)
<span class="co">#&gt; [1] 42703.15</span></code></pre></div>
<p><strong>Random Forest</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rf &lt;-<span class="st"> </span>RFTrainer<span class="op">$</span><span class="kw">new</span>(<span class="dt">n_estimators =</span> <span class="dv">500</span>,<span class="dt">classification =</span> <span class="dv">0</span>)
rf<span class="op">$</span><span class="kw">fit</span>(<span class="dt">X =</span> xtrain, <span class="dt">y =</span> <span class="st">&quot;SalePrice&quot;</span>)
pred &lt;-<span class="st"> </span>rf<span class="op">$</span><span class="kw">predict</span>(<span class="dt">df =</span> xtest)
rf<span class="op">$</span><span class="kw">get_importance</span>()
<span class="co">#&gt;               tmp.order.tmp..decreasing...TRUE..</span>
<span class="co">#&gt; OverallQual                         833522821412</span>
<span class="co">#&gt; GarageCars                          511723048043</span>
<span class="co">#&gt; 1stFlrSF                            487579913708</span>
<span class="co">#&gt; GarageArea                          476300688798</span>
<span class="co">#&gt; YearBuilt                           334600066921</span>
<span class="co">#&gt; GarageYrBlt                         289720646078</span>
<span class="co">#&gt; BsmtQual                            243160542356</span>
<span class="co">#&gt; FullBath                            235944573775</span>
<span class="co">#&gt; BsmtFinSF1                          226109516264</span>
<span class="co">#&gt; LotArea                             190775857067</span>
<span class="co">#&gt; TotRmsAbvGrd                        181715819545</span>
<span class="co">#&gt; ExterQual                           164478784067</span>
<span class="co">#&gt; 2ndFlrSF                            158445105373</span>
<span class="co">#&gt; YearRemodAdd                        156415339696</span>
<span class="co">#&gt; FireplaceQu                         154146120124</span>
<span class="co">#&gt; MasVnrArea                          151111410362</span>
<span class="co">#&gt; KitchenQual                         145425099126</span>
<span class="co">#&gt; Fireplaces                          132307912524</span>
<span class="co">#&gt; Foundation                           84719540738</span>
<span class="co">#&gt; LotFrontage                          83223657687</span>
<span class="co">#&gt; OpenPorchSF                          75956468846</span>
<span class="co">#&gt; BsmtUnfSF                            68403366235</span>
<span class="co">#&gt; BsmtFinType1                         58318976374</span>
<span class="co">#&gt; WoodDeckSF                           52193697598</span>
<span class="co">#&gt; MoSold                               50892512614</span>
<span class="co">#&gt; Neighborhood                         47969974511</span>
<span class="co">#&gt; GarageType                           44714661421</span>
<span class="co">#&gt; BedroomAbvGr                         41177535283</span>
<span class="co">#&gt; Exterior2nd                          37101388425</span>
<span class="co">#&gt; OverallCond                          36263108617</span>
<span class="co">#&gt; MSSubClass                           36195306670</span>
<span class="co">#&gt; BsmtExposure                         34226511518</span>
<span class="co">#&gt; HeatingQC                            32453111883</span>
<span class="co">#&gt; HalfBath                             31636584989</span>
<span class="co">#&gt; Exterior1st                          30180400616</span>
<span class="co">#&gt; MasVnrType                           28031581303</span>
<span class="co">#&gt; RoofStyle                            26991326319</span>
<span class="co">#&gt; HouseStyle                           25414867454</span>
<span class="co">#&gt; GarageFinish                         24699970434</span>
<span class="co">#&gt; RoofMatl                             22817636141</span>
<span class="co">#&gt; BsmtFullBath                         22341583078</span>
<span class="co">#&gt; LotShape                             21448628218</span>
<span class="co">#&gt; YrSold                               20978233868</span>
<span class="co">#&gt; MSZoning                             19494522596</span>
<span class="co">#&gt; LandContour                          18220837783</span>
<span class="co">#&gt; SaleCondition                        14891216640</span>
<span class="co">#&gt; EnclosedPorch                        13536859215</span>
<span class="co">#&gt; ScreenPorch                          13474805603</span>
<span class="co">#&gt; BldgType                             13464188196</span>
<span class="co">#&gt; BsmtHalfBath                         12944253127</span>
<span class="co">#&gt; GarageQual                           12273757801</span>
<span class="co">#&gt; Condition1                           11647247111</span>
<span class="co">#&gt; CentralAir                           11547411940</span>
<span class="co">#&gt; LandSlope                            11500933603</span>
<span class="co">#&gt; SaleType                             11394049360</span>
<span class="co">#&gt; GarageCond                           10978456317</span>
<span class="co">#&gt; LotConfig                             9268886861</span>
<span class="co">#&gt; BsmtFinSF2                            9085854718</span>
<span class="co">#&gt; BsmtFinType2                          6853792279</span>
<span class="co">#&gt; ExterCond                             5947208856</span>
<span class="co">#&gt; Functional                            5805977081</span>
<span class="co">#&gt; Fence                                 5637835972</span>
<span class="co">#&gt; BsmtCond                              5527721261</span>
<span class="co">#&gt; KitchenAbvGr                          5125635948</span>
<span class="co">#&gt; LowQualFinSF                          4137899715</span>
<span class="co">#&gt; PavedDrive                            4028037666</span>
<span class="co">#&gt; Heating                               2819736225</span>
<span class="co">#&gt; Condition2                            2784817722</span>
<span class="co">#&gt; Electrical                            2170052792</span>
<span class="co">#&gt; 3SsnPorch                             1958900857</span>
<span class="co">#&gt; MiscVal                               1816695047</span>
<span class="co">#&gt; Street                                 489177735</span>
<span class="co">#&gt; PoolArea                               194172431</span>
<span class="co">#&gt; Utilities                                      0</span>
<span class="kw">rmse</span>(<span class="dt">actual =</span> xtest<span class="op">$</span>SalePrice, <span class="dt">predicted =</span> pred)
<span class="co">#&gt; [1] 33924.94</span></code></pre></div>
<p><strong>Xgboost</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">xgb &lt;-<span class="st"> </span>XGBTrainer<span class="op">$</span><span class="kw">new</span>(<span class="dt">objective =</span> <span class="st">&quot;reg:linear&quot;</span>
                      , <span class="dt">n_estimators =</span> <span class="dv">500</span>
                      , <span class="dt">eval_metric =</span> <span class="st">&quot;rmse&quot;</span>
                      , <span class="dt">maximize =</span> F
                      , <span class="dt">learning_rate =</span> <span class="fl">0.1</span>
                      ,<span class="dt">max_depth =</span> <span class="dv">6</span>)
xgb<span class="op">$</span><span class="kw">fit</span>(<span class="dt">X =</span> xtrain, <span class="dt">y =</span> <span class="st">&quot;SalePrice&quot;</span>, <span class="dt">valid =</span> xtest)
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-rmse:178677.218750    val-rmse:179860.609375 </span>
<span class="co">#&gt; [51] train-rmse:8639.050781  val-rmse:35170.535156 </span>
<span class="co">#&gt; [101]    train-rmse:5012.278320  val-rmse:33791.890625 </span>
<span class="co">#&gt; [151]    train-rmse:3328.215088  val-rmse:33500.906250 </span>
<span class="co">#&gt; [201]    train-rmse:2106.097656  val-rmse:33373.820312 </span>
<span class="co">#&gt; [251]    train-rmse:1484.432861  val-rmse:33339.132812 </span>
<span class="co">#&gt; [301]    train-rmse:1009.036682  val-rmse:33312.246094 </span>
<span class="co">#&gt; [351]    train-rmse:680.185913   val-rmse:33291.863281 </span>
<span class="co">#&gt; [401]    train-rmse:505.055695   val-rmse:33283.257812 </span>
<span class="co">#&gt; [451]    train-rmse:371.380035   val-rmse:33280.609375 </span>
<span class="co">#&gt; [500]    train-rmse:282.667938   val-rmse:33279.257812</span>
pred &lt;-<span class="st"> </span>xgb<span class="op">$</span><span class="kw">predict</span>(xtest)
<span class="kw">rmse</span>(<span class="dt">actual =</span> xtest<span class="op">$</span>SalePrice, <span class="dt">predicted =</span> pred)
<span class="co">#&gt; [1] 33279.26</span></code></pre></div>
<p><strong>Grid Search</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">xgb &lt;-<span class="st"> </span>XGBTrainer<span class="op">$</span><span class="kw">new</span>(<span class="dt">objective=</span><span class="st">&quot;reg:linear&quot;</span>)

gst &lt;-GridSearchCV<span class="op">$</span><span class="kw">new</span>(<span class="dt">trainer =</span> xgb,
                             <span class="dt">parameters =</span> <span class="kw">list</span>(<span class="dt">n_estimators =</span> <span class="kw">c</span>(<span class="dv">10</span>,<span class="dv">50</span>), <span class="dt">max_depth =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">2</span>)),
                             <span class="dt">n_folds =</span> <span class="dv">3</span>,
                             <span class="dt">scoring =</span> <span class="kw">c</span>(<span class="st">'accuracy'</span>,<span class="st">'auc'</span>))
gst<span class="op">$</span><span class="kw">fit</span>(xtrain, <span class="st">&quot;SalePrice&quot;</span>)
<span class="co">#&gt; [1] &quot;entering grid search&quot;</span>
<span class="co">#&gt; [1] &quot;In total, 4 models will be trained&quot;</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-rmse:140195.515625 </span>
<span class="co">#&gt; [10] train-rmse:15211.144531</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-rmse:144265.859375 </span>
<span class="co">#&gt; [10] train-rmse:16491.615234</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-rmse:141077.531250 </span>
<span class="co">#&gt; [10] train-rmse:15997.720703</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-rmse:140195.515625 </span>
<span class="co">#&gt; [50] train-rmse:3664.224121</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-rmse:144265.859375 </span>
<span class="co">#&gt; [50] train-rmse:4077.007568</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-rmse:141077.531250 </span>
<span class="co">#&gt; [50] train-rmse:3878.576660</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-rmse:140853.265625 </span>
<span class="co">#&gt; [10] train-rmse:29302.730469</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-rmse:145067.578125 </span>
<span class="co">#&gt; [10] train-rmse:32326.396484</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-rmse:141824.375000 </span>
<span class="co">#&gt; [10] train-rmse:28798.119141</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-rmse:140853.265625 </span>
<span class="co">#&gt; [50] train-rmse:16483.222656</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-rmse:145067.578125 </span>
<span class="co">#&gt; [50] train-rmse:17453.232422</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-rmse:141824.375000 </span>
<span class="co">#&gt; [50] train-rmse:15867.968750</span>
gst<span class="op">$</span><span class="kw">best_iteration</span>()
<span class="co">#&gt; $n_estimators</span>
<span class="co">#&gt; [1] 10</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $max_depth</span>
<span class="co">#&gt; [1] 5</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $accuracy_avg</span>
<span class="co">#&gt; [1] 0</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $accuracy_sd</span>
<span class="co">#&gt; [1] 0</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $auc_avg</span>
<span class="co">#&gt; [1] NaN</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $auc_sd</span>
<span class="co">#&gt; [1] NA</span></code></pre></div>
<p><strong>Random Search</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rf &lt;-<span class="st"> </span>RFTrainer<span class="op">$</span><span class="kw">new</span>()
rst &lt;-RandomSearchCV<span class="op">$</span><span class="kw">new</span>(<span class="dt">trainer =</span> rf,
                             <span class="dt">parameters =</span> <span class="kw">list</span>(<span class="dt">n_estimators =</span> <span class="kw">c</span>(<span class="dv">10</span>,<span class="dv">50</span>),
                             <span class="dt">max_depth =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">2</span>)),
                             <span class="dt">n_folds =</span> <span class="dv">3</span>,
                             <span class="dt">scoring =</span> <span class="kw">c</span>(<span class="st">'accuracy'</span>,<span class="st">'auc'</span>),
                             <span class="dt">n_iter=</span><span class="dv">3</span>)
rst<span class="op">$</span><span class="kw">fit</span>(xtrain, <span class="st">&quot;SalePrice&quot;</span>)
<span class="co">#&gt; [1] &quot;In total, 3 models will be trained&quot;</span>
rst<span class="op">$</span><span class="kw">best_iteration</span>()
<span class="co">#&gt; $n_estimators</span>
<span class="co">#&gt; [1] 10</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $max_depth</span>
<span class="co">#&gt; [1] 5</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $accuracy_avg</span>
<span class="co">#&gt; [1] 0.009766596</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $accuracy_sd</span>
<span class="co">#&gt; [1] 0.004482377</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $auc_avg</span>
<span class="co">#&gt; [1] NaN</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $auc_sd</span>
<span class="co">#&gt; [1] NA</span></code></pre></div>
</div>
<div id="binary-classification-data" class="section level3">
<h3>Binary Classification Data</h3>
<p>Here, we will solve a simple binary classification problem (predict people who survived on titanic ship). The idea here is to demonstrate how to use this package to solve classification problems.</p>
<p><strong>Data Preparation</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># load class</span>
<span class="kw">load</span>(<span class="st">'../data/cla_train.rda'</span>)
<span class="co"># if the above doesn't work, you can try: load(&quot;cla_train.rda&quot;)</span>

<span class="kw">head</span>(cla_train)
<span class="co">#&gt;    PassengerId Survived Pclass</span>
<span class="co">#&gt; 1:           1        0      3</span>
<span class="co">#&gt; 2:           2        1      1</span>
<span class="co">#&gt; 3:           3        1      3</span>
<span class="co">#&gt; 4:           4        1      1</span>
<span class="co">#&gt; 5:           5        0      3</span>
<span class="co">#&gt; 6:           6        0      3</span>
<span class="co">#&gt;                                                   Name    Sex Age SibSp</span>
<span class="co">#&gt; 1:                             Braund, Mr. Owen Harris   male  22     1</span>
<span class="co">#&gt; 2: Cumings, Mrs. John Bradley (Florence Briggs Thayer) female  38     1</span>
<span class="co">#&gt; 3:                              Heikkinen, Miss. Laina female  26     0</span>
<span class="co">#&gt; 4:        Futrelle, Mrs. Jacques Heath (Lily May Peel) female  35     1</span>
<span class="co">#&gt; 5:                            Allen, Mr. William Henry   male  35     0</span>
<span class="co">#&gt; 6:                                    Moran, Mr. James   male  NA     0</span>
<span class="co">#&gt;    Parch           Ticket    Fare Cabin Embarked</span>
<span class="co">#&gt; 1:     0        A/5 21171  7.2500              S</span>
<span class="co">#&gt; 2:     0         PC 17599 71.2833   C85        C</span>
<span class="co">#&gt; 3:     0 STON/O2. 3101282  7.9250              S</span>
<span class="co">#&gt; 4:     0           113803 53.1000  C123        S</span>
<span class="co">#&gt; 5:     0           373450  8.0500              S</span>
<span class="co">#&gt; 6:     0           330877  8.4583              Q</span>

<span class="co"># split the data</span>
split &lt;-<span class="st"> </span><span class="kw">createDataPartition</span>(<span class="dt">y =</span> cla_train<span class="op">$</span>Survived,<span class="dt">p =</span> <span class="fl">0.7</span>)
xtrain &lt;-<span class="st"> </span>cla_train[split<span class="op">$</span>Resample1]
xtest &lt;-<span class="st"> </span>cla_train[<span class="op">!</span>split<span class="op">$</span>Resample1]

<span class="co"># encode categorical variables - shorter way</span>
<span class="cf">for</span>(c <span class="cf">in</span> <span class="kw">c</span>(<span class="st">'Embarked'</span>,<span class="st">'Sex'</span>,<span class="st">'Cabin'</span>)){
    lbl &lt;-<span class="st"> </span>LabelEncoder<span class="op">$</span><span class="kw">new</span>()
    lbl<span class="op">$</span><span class="kw">fit</span>(<span class="kw">c</span>(xtrain[[c]], xtest[[c]]))
    xtrain[[c]] &lt;-<span class="st"> </span>lbl<span class="op">$</span><span class="kw">transform</span>(xtrain[[c]])
    xtest[[c]] &lt;-<span class="st"> </span>lbl<span class="op">$</span><span class="kw">transform</span>(xtest[[c]])
}
<span class="co">#&gt; The data contains blank values. Imputing them with 'NA' </span>
<span class="co">#&gt; The data contains blank values. Imputing them with 'NA' </span>
<span class="co">#&gt; The data contains blank values. Imputing them with 'NA' </span>
<span class="co">#&gt; The data contains blank values. Imputing them with 'NA' </span>
<span class="co">#&gt; The data contains blank values. Imputing them with 'NA'</span>

<span class="co"># impute missing values</span>
xtrain[, Age <span class="op">:</span><span class="er">=</span><span class="st"> </span><span class="kw">replace</span>(Age, <span class="kw">is.na</span>(Age), <span class="kw">median</span>(Age, <span class="dt">na.rm =</span> T))]
xtest[, Age <span class="op">:</span><span class="er">=</span><span class="st"> </span><span class="kw">replace</span>(Age, <span class="kw">is.na</span>(Age), <span class="kw">median</span>(Age, <span class="dt">na.rm =</span> T))]

<span class="co"># drop these features</span>
to_drop &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">'PassengerId'</span>,<span class="st">'Ticket'</span>,<span class="st">'Name'</span>)

xtrain &lt;-<span class="st"> </span>xtrain[,<span class="op">-</span><span class="kw">c</span>(to_drop), with=F]
xtest &lt;-<span class="st"> </span>xtest[,<span class="op">-</span><span class="kw">c</span>(to_drop), with=F]</code></pre></div>
<p>Now, our data is ready to be served for model training. Let’s do it.</p>
<p><strong>KNN Classification</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knn &lt;-<span class="st"> </span>KNNTrainer<span class="op">$</span><span class="kw">new</span>(<span class="dt">k =</span> <span class="dv">2</span>,<span class="dt">prob =</span> T,<span class="dt">type =</span> <span class="st">'class'</span>)
knn<span class="op">$</span><span class="kw">fit</span>(<span class="dt">train =</span> xtrain, <span class="dt">test =</span> xtest, <span class="dt">y =</span> <span class="st">'Survived'</span>)
probs &lt;-<span class="st"> </span>knn<span class="op">$</span><span class="kw">predict</span>(<span class="dt">type =</span> <span class="st">'prob'</span>)
labels &lt;-<span class="st"> </span>knn<span class="op">$</span><span class="kw">predict</span>(<span class="dt">type=</span><span class="st">'raw'</span>)
<span class="kw">auc</span>(<span class="dt">actual =</span> xtest<span class="op">$</span>Survived, <span class="dt">predicted=</span>labels)
<span class="co">#&gt; [1] 0.6637255</span></code></pre></div>
<p><strong>Naive Bayes Classification</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">nb &lt;-<span class="st"> </span>NBTrainer<span class="op">$</span><span class="kw">new</span>()
nb<span class="op">$</span><span class="kw">fit</span>(xtrain, <span class="st">'Survived'</span>)
pred &lt;-<span class="st"> </span>nb<span class="op">$</span><span class="kw">predict</span>(xtest)
<span class="kw">auc</span>(<span class="dt">actual =</span> xtest<span class="op">$</span>Survived, <span class="dt">predicted=</span>pred)
<span class="co">#&gt; [1] 0.7409982</span></code></pre></div>
<p><strong>SVM Classification</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#predicts labels</span>
svm &lt;-<span class="st"> </span>SVMTrainer<span class="op">$</span><span class="kw">new</span>()
<span class="co">#&gt; [1] &quot;For classification, target variable must be factor type. For regression, target variable must be numeric type.&quot;</span>
svm<span class="op">$</span><span class="kw">fit</span>(xtrain, <span class="st">'Survived'</span>)
pred &lt;-<span class="st"> </span>svm<span class="op">$</span><span class="kw">predict</span>(xtest)
<span class="kw">auc</span>(<span class="dt">actual =</span> xtest<span class="op">$</span>Survived, <span class="dt">predicted=</span>pred)
<span class="co">#&gt; [1] 0.8447712</span></code></pre></div>
<p><strong>Logistic Regression</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lf &lt;-<span class="st"> </span>LMTrainer<span class="op">$</span><span class="kw">new</span>(<span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>)
lf<span class="op">$</span><span class="kw">fit</span>(<span class="dt">X =</span> xtrain, <span class="dt">y =</span> <span class="st">&quot;Survived&quot;</span>)
<span class="kw">summary</span>(lf<span class="op">$</span>model)
<span class="co">#&gt; </span>
<span class="co">#&gt; Call:</span>
<span class="co">#&gt; stats::glm(formula = f, family = self$family, data = X, weights = self$weights)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Deviance Residuals: </span>
<span class="co">#&gt;     Min       1Q   Median       3Q      Max  </span>
<span class="co">#&gt; -2.5085  -0.5588  -0.4155   0.6339   2.4082  </span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Coefficients:</span>
<span class="co">#&gt;              Estimate Std. Error z value Pr(&gt;|z|)    </span>
<span class="co">#&gt; (Intercept)  1.471013   0.629914   2.335 0.019530 *  </span>
<span class="co">#&gt; Pclass      -0.892178   0.184012  -4.848 1.24e-06 ***</span>
<span class="co">#&gt; Sex          2.838180   0.242342  11.711  &lt; 2e-16 ***</span>
<span class="co">#&gt; Age         -0.036018   0.009574  -3.762 0.000169 ***</span>
<span class="co">#&gt; SibSp       -0.177886   0.129302  -1.376 0.168903    </span>
<span class="co">#&gt; Parch       -0.424609   0.167448  -2.536 0.011220 *  </span>
<span class="co">#&gt; Fare         0.000997   0.002600   0.383 0.701399    </span>
<span class="co">#&gt; Cabin        0.014729   0.004721   3.120 0.001808 ** </span>
<span class="co">#&gt; Embarked     0.074928   0.140586   0.533 0.594051    </span>
<span class="co">#&gt; ---</span>
<span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span>
<span class="co">#&gt; </span>
<span class="co">#&gt;     Null deviance: 831.52  on 623  degrees of freedom</span>
<span class="co">#&gt; Residual deviance: 539.22  on 615  degrees of freedom</span>
<span class="co">#&gt; AIC: 557.22</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; Number of Fisher Scoring iterations: 5</span>
predictions &lt;-<span class="st"> </span>lf<span class="op">$</span><span class="kw">predict</span>(<span class="dt">df =</span> xtest)
<span class="kw">auc</span>(<span class="dt">actual =</span> xtest<span class="op">$</span>Survived, <span class="dt">predicted =</span> predictions)
<span class="co">#&gt; [1] 0.8123292</span></code></pre></div>
<p><strong>Lasso Logistic Regression</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lf &lt;-<span class="st"> </span>LMTrainer<span class="op">$</span><span class="kw">new</span>(<span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>, <span class="dt">alpha=</span><span class="dv">1</span>)
lf<span class="op">$</span><span class="kw">cv_model</span>(<span class="dt">X =</span> xtrain, <span class="dt">y =</span> <span class="st">&quot;Survived&quot;</span>, <span class="dt">nfolds =</span> <span class="dv">5</span>, <span class="dt">parallel =</span> <span class="ot">FALSE</span>)
<span class="co">#&gt; Computation done.</span>
pred &lt;-<span class="st"> </span>lf<span class="op">$</span><span class="kw">cv_predict</span>(<span class="dt">df =</span> xtest)
<span class="kw">auc</span>(<span class="dt">actual =</span> xtest<span class="op">$</span>Survived, <span class="dt">predicted =</span> pred)
<span class="co">#&gt; [1] 0.8060903</span></code></pre></div>
<p><strong>Ridge Logistic Regression</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lf &lt;-<span class="st"> </span>LMTrainer<span class="op">$</span><span class="kw">new</span>(<span class="dt">family=</span><span class="st">&quot;binomial&quot;</span>, <span class="dt">alpha=</span><span class="dv">0</span>)
lf<span class="op">$</span><span class="kw">cv_model</span>(<span class="dt">X =</span> xtrain, <span class="dt">y =</span> <span class="st">&quot;Survived&quot;</span>, <span class="dt">nfolds =</span> <span class="dv">5</span>, <span class="dt">parallel =</span> <span class="ot">FALSE</span>)
<span class="co">#&gt; Computation done.</span>
pred &lt;-<span class="st"> </span>lf<span class="op">$</span><span class="kw">cv_predict</span>(<span class="dt">df =</span> xtest)
<span class="kw">auc</span>(<span class="dt">actual =</span> xtest<span class="op">$</span>Survived, <span class="dt">predicted =</span> pred)
<span class="co">#&gt; [1] 0.8000297</span></code></pre></div>
<p><strong>Random Forest</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rf &lt;-<span class="st"> </span>RFTrainer<span class="op">$</span><span class="kw">new</span>(<span class="dt">n_estimators =</span> <span class="dv">500</span>,<span class="dt">classification =</span> <span class="dv">1</span>, <span class="dt">max_features =</span> <span class="dv">3</span>)
rf<span class="op">$</span><span class="kw">fit</span>(<span class="dt">X =</span> xtrain, <span class="dt">y =</span> <span class="st">&quot;Survived&quot;</span>)

pred &lt;-<span class="st"> </span>rf<span class="op">$</span><span class="kw">predict</span>(<span class="dt">df =</span> xtest)
rf<span class="op">$</span><span class="kw">get_importance</span>()
<span class="co">#&gt;          tmp.order.tmp..decreasing...TRUE..</span>
<span class="co">#&gt; Sex                               75.459878</span>
<span class="co">#&gt; Fare                              53.442346</span>
<span class="co">#&gt; Age                               44.549006</span>
<span class="co">#&gt; Cabin                             29.467851</span>
<span class="co">#&gt; Pclass                            23.635666</span>
<span class="co">#&gt; SibSp                             10.072035</span>
<span class="co">#&gt; Parch                              8.827820</span>
<span class="co">#&gt; Embarked                           7.384991</span>

<span class="kw">auc</span>(<span class="dt">actual =</span> xtest<span class="op">$</span>Survived, <span class="dt">predicted =</span> pred)
<span class="co">#&gt; [1] 0.8262032</span></code></pre></div>
<p><strong>Xgboost</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">xgb &lt;-<span class="st"> </span>XGBTrainer<span class="op">$</span><span class="kw">new</span>(<span class="dt">objective =</span> <span class="st">&quot;binary:logistic&quot;</span>
                      , <span class="dt">n_estimators =</span> <span class="dv">500</span>
                      , <span class="dt">eval_metric =</span> <span class="st">&quot;auc&quot;</span>
                      , <span class="dt">maximize =</span> T
                      , <span class="dt">learning_rate =</span> <span class="fl">0.1</span>
                      ,<span class="dt">max_depth =</span> <span class="dv">6</span>)
xgb<span class="op">$</span><span class="kw">fit</span>(<span class="dt">X =</span> xtrain, <span class="dt">y =</span> <span class="st">&quot;Survived&quot;</span>, <span class="dt">valid =</span> xtest)
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-auc:0.879905  val-auc:0.852169 </span>
<span class="co">#&gt; [51] train-auc:0.970513  val-auc:0.847950 </span>
<span class="co">#&gt; [101]    train-auc:0.984288  val-auc:0.849733 </span>
<span class="co">#&gt; [151]    train-auc:0.989437  val-auc:0.852941 </span>
<span class="co">#&gt; [201]    train-auc:0.993094  val-auc:0.855377 </span>
<span class="co">#&gt; [251]    train-auc:0.995426  val-auc:0.854813 </span>
<span class="co">#&gt; [301]    train-auc:0.996739  val-auc:0.854159 </span>
<span class="co">#&gt; [351]    train-auc:0.997488  val-auc:0.855051 </span>
<span class="co">#&gt; [401]    train-auc:0.997998  val-auc:0.855110 </span>
<span class="co">#&gt; [451]    train-auc:0.998280  val-auc:0.854813 </span>
<span class="co">#&gt; [500]    train-auc:0.998486  val-auc:0.855229</span>

pred &lt;-<span class="st"> </span>xgb<span class="op">$</span><span class="kw">predict</span>(xtest)
<span class="kw">auc</span>(<span class="dt">actual =</span> xtest<span class="op">$</span>Survived, <span class="dt">predicted =</span> pred)
<span class="co">#&gt; [1] 0.8552288</span></code></pre></div>
<p><strong>Grid Search</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">xgb &lt;-<span class="st"> </span>XGBTrainer<span class="op">$</span><span class="kw">new</span>(<span class="dt">objective=</span><span class="st">&quot;binary:logistic&quot;</span>)
gst &lt;-GridSearchCV<span class="op">$</span><span class="kw">new</span>(<span class="dt">trainer =</span> xgb,
                             <span class="dt">parameters =</span> <span class="kw">list</span>(<span class="dt">n_estimators =</span> <span class="kw">c</span>(<span class="dv">10</span>,<span class="dv">50</span>),
                             <span class="dt">max_depth =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">2</span>)),
                             <span class="dt">n_folds =</span> <span class="dv">3</span>,
                             <span class="dt">scoring =</span> <span class="kw">c</span>(<span class="st">'accuracy'</span>,<span class="st">'auc'</span>))
gst<span class="op">$</span><span class="kw">fit</span>(xtrain, <span class="st">&quot;Survived&quot;</span>)
<span class="co">#&gt; [1] &quot;entering grid search&quot;</span>
<span class="co">#&gt; [1] &quot;In total, 4 models will be trained&quot;</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-error:0.144231 </span>
<span class="co">#&gt; [10] train-error:0.115385</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-error:0.108173 </span>
<span class="co">#&gt; [10] train-error:0.084135</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-error:0.141827 </span>
<span class="co">#&gt; [10] train-error:0.108173</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-error:0.144231 </span>
<span class="co">#&gt; [50] train-error:0.038462</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-error:0.108173 </span>
<span class="co">#&gt; [50] train-error:0.045673</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-error:0.141827 </span>
<span class="co">#&gt; [50] train-error:0.040865</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-error:0.213942 </span>
<span class="co">#&gt; [10] train-error:0.175481</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-error:0.177885 </span>
<span class="co">#&gt; [10] train-error:0.134615</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-error:0.209135 </span>
<span class="co">#&gt; [10] train-error:0.165865</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-error:0.213942 </span>
<span class="co">#&gt; [50] train-error:0.115385</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-error:0.177885 </span>
<span class="co">#&gt; [50] train-error:0.100962</span>
<span class="co">#&gt; converting the data into xgboost format..</span>
<span class="co">#&gt; starting with training...</span>
<span class="co">#&gt; [1]  train-error:0.209135 </span>
<span class="co">#&gt; [50] train-error:0.125000</span>
gst<span class="op">$</span><span class="kw">best_iteration</span>()
<span class="co">#&gt; $n_estimators</span>
<span class="co">#&gt; [1] 10</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $max_depth</span>
<span class="co">#&gt; [1] 5</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $accuracy_avg</span>
<span class="co">#&gt; [1] 0</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $accuracy_sd</span>
<span class="co">#&gt; [1] 0</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $auc_avg</span>
<span class="co">#&gt; [1] 0.8450953</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $auc_sd</span>
<span class="co">#&gt; [1] 0.05599903</span></code></pre></div>
<p><strong>Random Search</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rf &lt;-<span class="st"> </span>RFTrainer<span class="op">$</span><span class="kw">new</span>()
rst &lt;-RandomSearchCV<span class="op">$</span><span class="kw">new</span>(<span class="dt">trainer =</span> rf,
                             <span class="dt">parameters =</span> <span class="kw">list</span>(<span class="dt">n_estimators =</span> <span class="kw">c</span>(<span class="dv">10</span>,<span class="dv">50</span>),
                             <span class="dt">max_depth =</span> <span class="kw">c</span>(<span class="dv">5</span>,<span class="dv">2</span>)),
                             <span class="dt">n_folds =</span> <span class="dv">3</span>,
                             <span class="dt">scoring =</span> <span class="kw">c</span>(<span class="st">'accuracy'</span>,<span class="st">'auc'</span>),
                             <span class="dt">n_iter =</span> <span class="dv">3</span>)
rst<span class="op">$</span><span class="kw">fit</span>(xtrain, <span class="st">&quot;Survived&quot;</span>)
<span class="co">#&gt; [1] &quot;In total, 3 models will be trained&quot;</span>
rst<span class="op">$</span><span class="kw">best_iteration</span>()
<span class="co">#&gt; $n_estimators</span>
<span class="co">#&gt; [1] 10</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $max_depth</span>
<span class="co">#&gt; [1] 2</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $accuracy_avg</span>
<span class="co">#&gt; [1] 0.8060897</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $accuracy_sd</span>
<span class="co">#&gt; [1] 0.01943006</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $auc_avg</span>
<span class="co">#&gt; [1] 0.7810661</span>
<span class="co">#&gt; </span>
<span class="co">#&gt; $auc_sd</span>
<span class="co">#&gt; [1] 0.0187002</span></code></pre></div>
<p>Let’s create some new feature based on target variable using target encoding and test a model.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># add target encoding features</span>
xtrain[, feat_<span class="dv">01</span> <span class="op">:</span><span class="er">=</span><span class="st"> </span><span class="kw">smoothMean</span>(<span class="dt">train_df =</span> xtrain,
                        <span class="dt">test_df =</span> xtest,
                        <span class="dt">colname =</span> <span class="st">&quot;Embarked&quot;</span>,
                        <span class="dt">target =</span> <span class="st">&quot;Survived&quot;</span>)<span class="op">$</span>train[[<span class="dv">2</span>]]]
xtest[, feat_<span class="dv">01</span> <span class="op">:</span><span class="er">=</span><span class="st"> </span><span class="kw">smoothMean</span>(<span class="dt">train_df =</span> xtrain,
                               <span class="dt">test_df =</span> xtest,
                               <span class="dt">colname =</span> <span class="st">&quot;Embarked&quot;</span>,
                               <span class="dt">target =</span> <span class="st">&quot;Survived&quot;</span>)<span class="op">$</span>test[[<span class="dv">2</span>]]]

<span class="co"># train a random forest</span>
<span class="co"># Random Forest</span>
rf &lt;-<span class="st"> </span>RFTrainer<span class="op">$</span><span class="kw">new</span>(<span class="dt">n_estimators =</span> <span class="dv">500</span>,<span class="dt">classification =</span> <span class="dv">1</span>, <span class="dt">max_features =</span> <span class="dv">4</span>)
rf<span class="op">$</span><span class="kw">fit</span>(<span class="dt">X =</span> xtrain, <span class="dt">y =</span> <span class="st">&quot;Survived&quot;</span>)
pred &lt;-<span class="st"> </span>rf<span class="op">$</span><span class="kw">predict</span>(<span class="dt">df =</span> xtest)
rf<span class="op">$</span><span class="kw">get_importance</span>()
<span class="co">#&gt;          tmp.order.tmp..decreasing...TRUE..</span>
<span class="co">#&gt; Sex                               76.938777</span>
<span class="co">#&gt; Fare                              58.064138</span>
<span class="co">#&gt; Age                               48.804344</span>
<span class="co">#&gt; Cabin                             30.301633</span>
<span class="co">#&gt; Pclass                            24.581820</span>
<span class="co">#&gt; SibSp                              9.661118</span>
<span class="co">#&gt; Parch                              7.962772</span>
<span class="co">#&gt; Embarked                           4.554117</span>
<span class="co">#&gt; feat_01                            4.550936</span>

<span class="kw">auc</span>(<span class="dt">actual =</span> xtest<span class="op">$</span>Survived, <span class="dt">predicted =</span> pred)
<span class="co">#&gt; [1] 0.8262032</span></code></pre></div>
</div>
</div>



<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
